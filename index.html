
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chuhan Li</title>
  
  <meta name="author" content="Chuhan Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/giraffe.PNG">
</head>

<body>
<!-- <body style="background-color:rgb(240,240,240);"> -->
	<table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr style="padding:0px">
	<td style="padding:0px">

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr style="padding:0px">

			<td style="padding:2.5%;width:60%;vertical-align:middle">
				<p style="text-align:left">
					<name>Chuhan Li ÈªéÊ•öÊ∂µ</name>
				</p>
        		Master Student @
        		<strong><a href="https://nlp.cs.yale.edu/">Yale NLP</a></strong>, 
            <strong><a href="https://graph-and-geometric-learning.github.io/">Graph and Geometric Learning Lab</a></strong>
            <br>
        		Department of Computer Science, <strong><a href="https://cpsc.yale.edu/">Yale University</a></strong>
      			
      			<p></p>

                <strong>Email:</strong> chuhan.li.cl2575 [at] yale [dot] edu <br>
                <strong>Office:</strong> 17 Hillhouse Avenue, Room 333
      			
      			<p></p>

      			<div style="text-align:center">
        			<strong><a href="https://scholar.google.com/citations?user=wRdg5fQAAAAJ&hl=en">Google Scholar</a></strong>
        			|
        			<strong><a href="https://x.com/_Chuhan_Li">X</a></strong>
        			|
              <strong><a href="https://www.linkedin.com/in/hugo-chuhan-li/">LinkedIn</a></strong>
              |
        			<strong><a href="https://github.com/LeeChuh">GitHub</a></strong>
      			</div>
			</td>

			<td style="width:20%;max-width:20%">
  				<img style="width:100%;max-width:80%" alt="profile photo" src="images/headshot.jpeg" class="hoverZoomLink">
			</td>

		</tr>
	</tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          I am a second year master's student in Computer Science at Yale University advised by <strong><a href="https://armancohan.com/">Arman Cohan</a></strong> and <strong><a href="https://www.cs.yale.edu/homes/ying-rex/">Rex Ying</a></strong>. I graduated <i>Summa Cum Laude</i> from Boston University in 2023 advised by <strong><a href="https://cs-people.bu.edu/evimaria/">Evimaria Terzi</a></strong>, where I obtained <i>B.A. in Computer Science</i> and <i>B.A. in Mathematics</i>.
          
          <br><br>
          
          My research interests include <strong>multimodal reasoning</strong>, <strong>neuro-symbolic reasoning</strong>, and <strong>geometric deep learning</strong>. 
          
          In the short term, I aim to enhance foundation models' capabilities in spatial-temporal reasoning, scientific reasoning, and domain-specific expertise across multiple modalities (images, videos).

          In the long term, I want to make AI systems to be able to interact with physical world via multimodal data.

         </td>
       </tr>
    </tbody></table>

	<!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
             <td style="padding:20px;width:100%;vertical-align:middle">
               <div style="color:#014240">
                 <strong>"The reality of the universe is geometrical."</strong>
                 &nbsp;&nbsp
                 -- <a href="https://en.wikipedia.org/wiki/Edwin_Arthur_Burtt">E. A. Burtt</a>. <i>The Metaphysical Foundations of Modern Physical Science</i>
                 <p></p>
                 "A scientific theory is usually felt to be better than its predecessors not only in the sense that it is a better instrument for discovering and solving puzzles but also <strong>because it is somehow a better representation of what nature is really like.</strong>"
                 &nbsp;&nbsp
                 -- <a href="https://en.wikipedia.org/wiki/Thomas_Kuhn">Thomas Kuhn</a>. <i>The Structure of Scientific Revolutions</i>
               </div>
             </td>
           </tr>
    </tbody></table> -->


<br>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
      <heading style="color: #00356b; font-weight: bold;">Research</heading>
  </tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<br>

  <!-- HybridMind -->
  <!-- <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
    <td style="padding:10px;width:20%;vertical-align:middle">
          <img style="width:100%;max-width:100%" alt="M3SciQA" src="projects/M3SciQA.png">
      <script type="text/javascript">
        function uflow_start() {
          document.getElementById('uflow_image').style.opacity = "1";
        }

        function uflow_stop() {
          document.getElementById('uflow_image').style.opacity = "0";
        }
        uflow_stop()
      </script>
    </td>
    <td style="padding:10px;width:80%;vertical-align:middle">
      <papertitle>HYBRIDMIND: Meta Selection of Natural Language and Symbolic Language for Enhanced LLM Reasoning</papertitle>
      <br>
      <a href="https://sophiahan6.github.io/">
        <author>Simeng Han*</author>
      </a>,
      <a href="https://helloworldlty.github.io/">
        <author>Tianyu Liu*</author>
      </a>,
      <u><b>Chuhan Li*</b></u>,
      <author>Xuyuan Xiong</author>,
      <a href="https://armancohan.com/">
        <author>Arman Cohan</author>
      </a>
      <br>
      <em>Findings of the Association for Computational Linguistics: EMNLP 2024</em>
      <span class="highlight"><strong>Oral</strong></span>
      <br>
      <strong><a href="https://arxiv.org/abs/2409.19381v5">Paper</a></strong>
      |
      <strong><a href="https://github.com/yale-nlp/M3SciQA">Code</a></strong>
      |
      <strong><a href="https://huggingface.co/datasets/yale-nlp/M3SciQA">Dataset</a></strong>
    </td>
  </tr> -->

  <!-- TOMATO -->
  <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
    <td style="padding:10px;width:20%;vertical-align:middle">
          <img style="width:100%;max-width:100%" alt="tomato" src="projects/TOMATO.png">
      <script type="text/javascript">
        function uflow_start() {
          document.getElementById('uflow_image').style.opacity = "1";
        }

        function uflow_stop() {
          document.getElementById('uflow_image').style.opacity = "0";
        }
        uflow_stop()
      </script>
    </td>
    <td style="padding:10px;width:80%;vertical-align:middle">
      <papertitle>üçÖ TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models</papertitle>
      <br>
      <a href="https://ziyaosg.github.io/">
        <author>Ziyao Shangguan*</author>
      </a>,
      <u><b>Chuhan Li*</b></u>,
      <a href="https://www.linkedin.com/in/eason-d-a23a302a9/">
        <author>Yuxuan Ding</author>
      </a>,
      <author>Yanan Zheng</author>
      ,
      <a href="https://yilunzhao.github.io/">
        <author>Yilun Zhao</author>
      </a>,
      <a href="https://www.tescafitzgerald.com/">
        <author>Tesca Fitzgerald</author>
      </a>,
      <a href="https://armancohan.com/">
        <author>Arman Cohan</author>
      </a>
      <br>
      <em>International Conference on Learning Representations (ICLR)</em>, 2025 
      <!-- <span class="highlight"><strong>Oral</strong></span> -->
      <br>
      <strong><a href="https://arxiv.org/abs/2410.23266">Paper</a></strong>
      |
      <strong><a href="https://github.com/yale-nlp/TOMATO">Code</a></strong>
      |
      <strong><a href="https://huggingface.co/datasets/yale-nlp/TOMATO">Dataset</a></strong>
    </td>
  </tr>

  <!-- M3SciQA -->
  <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
    <td style="padding:10px;width:20%;vertical-align:middle">
          <img style="width:100%;max-width:100%" alt="M3SciQA" src="projects/M3SciQA.png">
      <script type="text/javascript">
        function uflow_start() {
          document.getElementById('uflow_image').style.opacity = "1";
        }

        function uflow_stop() {
          document.getElementById('uflow_image').style.opacity = "0";
        }
        uflow_stop()
      </script>
    </td>
    <td style="padding:10px;width:80%;vertical-align:middle">
      <papertitle>M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models</papertitle>
      <br>
      <u><b>Chuhan Li*</b></u>,
      <a href="https://ziyaosg.github.io/">
        <author>Ziyao Shangguan*</author>
      </a>,
      <a href="https://yilunzhao.github.io/">
        <author>Yilun Zhao</author>
      </a>,
      <a href="https://www.linkedin.com/in/deyuan-li/">
        <author>Deyuan Li</author>
      </a>,
      <a href="https://yixinl7.github.io/">
        <author>Yixin Liu</author>
      </a>,
      <a href="https://armancohan.com/">
        <author>Arman Cohan</author>
      </a>
      <br>
      <em>Findings of the Association for Computational Linguistics: EMNLP 2024</em>
      <!-- <span class="highlight"><strong>Oral</strong></span> -->
      <br>
      <strong><a href="https://arxiv.org/abs/2411.04075">Paper</a></strong>
      |
      <strong><a href="https://github.com/yale-nlp/M3SciQA">Code</a></strong>
      |
      <strong><a href="https://huggingface.co/datasets/yale-nlp/M3SciQA">Dataset</a></strong>
    </td>
  </tr>


</tbody></table>

<br>


<!-- Professional Services -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
      <heading style="color: #00356b; font-weight: bold;">Professional Services</heading>
  </tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">


  <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <strong>Workshop Organizer:</strong>
          <ul>
            <li>4th workshop on 
              <a href="https://nenlp.github.io/spr2025/"><strong>New England NLP</strong></a> (NENLP), Apr 2025
            </li>
          </ul>
          <strong>Conference Reviewer:</strong> ICLR 2025, ACL 2025<br>
          </td>
        </tr>
</tbody>
</table>


<br>


<!-- Teaching  -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
      <heading style="color: #00356b; font-weight: bold;">Teaching</heading>
  </tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">


          <tr>
            <td style="padding:10px;width:20%;vertical-align:middle">
                  <img style="width:100%;max-width:100%" alt="yale_logo" src="images/yale_logo.png">
            </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
          	  Teaching Assistant, <strong><a href="https://nlp.cs.yale.edu/cpsc477/">Natural Language Processing</a></strong> (CPSC 477/577), Spring 2025
              <br>
              <br>
              Teaching Assistant, <strong><a href="https://graph-and-geometric-learning.github.io/cpsc483-583-website-24fall/#/">Deep Learning on Graph-Structured Data</a></strong> (CPSC 483/583), Fall 2024
              <br>
              <br>
              Teaching Assistant, <strong>Introduction to Machine Learning</strong> (CPSC 381), Spring 2024
              <br>
              <br>
              Teaching Assistant, <strong>Algorithms</strong> (CPSC 365), Fall 2023
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:20%;vertical-align:middle">
                  <img style="width:100%;max-width:100%" alt="bu_logo" src="images/bu_logo.png">
            </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
              Teaching Assistant, <strong>Combinatoric Structures</strong> (CS 131), Fall 2021, Spring 2022, Spring 2023
              <br>
              <br>
              Teaching Assistant, <strong>Foundation of Data Science</strong> (CS 365), Fall 2022
              <br>
              <br>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right">
                Website design from <a href="https://jonbarron.info/">Jon Barron</a>, source code <a href="https://github.com/jonbarron/website/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
